{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Part 0: Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part I just explore the data to understand better its properties and distribution, experiment with some ideas for text pre-processing, and use a number of \"classic\" ML methods to obtain a baseline for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SIZE: (14640, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                @VirginAmerica What @dhepburn said.   neutral\n",
       "1  @VirginAmerica plus you've added commercials t...  positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...   neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...  negative\n",
       "4  @VirginAmerica and it's a really big bad thing...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from the CSV file\n",
    "INPUT_PATH = 'twitter-airline-sentiment/Tweets.csv'\n",
    "raw_data = pd.read_csv(INPUT_PATH, header=0)\n",
    "\n",
    "df = raw_data.copy()[['text', 'airline_sentiment']]\n",
    "df = df.rename(columns={'airline_sentiment': 'sentiment'})\n",
    "\n",
    "print(\"DATA SIZE: \" + str(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>9178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "negative   9178\n",
       "neutral    3099\n",
       "positive   2363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset has 14640 tweets, of which the big majority (9178) are negative, 2363 are positive and there are some neutrals. We also see that are many Twitter handlers, which normally refer to entities. Let's check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of handlers = 889, with more than 1 occurrence = 193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('@united', 3893),\n",
       " ('@usairways', 2998),\n",
       " ('@americanair', 2961),\n",
       " ('@southwestair', 2458),\n",
       " ('@jetblue', 2248),\n",
       " ('@virginamerica', 518),\n",
       " ('@delta', 68),\n",
       " ('@imaginedragons', 45),\n",
       " ('@phlairport', 20),\n",
       " ('@dfwairport', 17),\n",
       " ('@wsj', 13),\n",
       " ('@ladygaga', 12),\n",
       " ('@carrieunderwood', 12),\n",
       " ('@fortunemagazine', 12),\n",
       " ('@love_dragonss', 10),\n",
       " ('@virginatlantic', 9),\n",
       " ('@flytpa', 9),\n",
       " ('@cowboycerrone', 9),\n",
       " ('@staralliance', 8),\n",
       " ('@gg8929', 8)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find the handlers\n",
    "from collections import Counter\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "\n",
    "def get_text_sequence(_df):\n",
    "    return (row.text for _, row in _df.iterrows())\n",
    "\n",
    "def get_all_handlers(text_it):\n",
    "    handler_counts = Counter()\n",
    "\n",
    "    tokenizer = TweetTokenizer(preserve_case=False)\n",
    "    \n",
    "    for text in text_it:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        handler_counts.update(t for t in tokens if len(t) > 1 and t.startswith('@'))\n",
    "\n",
    "    return handler_counts\n",
    "\n",
    "handler_counts = get_all_handlers(get_text_sequence(df))\n",
    "num_handlers_more_1 = sum(1 if c > 1 else 0 for c in handler_counts.values())\n",
    "print(\"Number of handlers = %d, with more than 1 occurrence = %d\" % (len(handler_counts), num_handlers_more_1))\n",
    "handler_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The huge majority of handlers refer to the airlines themselves, also considering that every tweet starts with one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing\n",
    "\n",
    "The other \"classic\" techniques that I will use as baseline normally require a more involved pre-processing:\n",
    "- All the tweets have a handler with the airline's company at the beginning (e.g. `@VirginAmerica`), I am removing them as they bring no additional information and actually could make the models to overfit, learning to classify according to the airline's name instead of the actual sentiment of the text.\n",
    "\n",
    "- `nltk` has a very handy `TweetTokenizer` ([documentation](https://www.nltk.org/api/nltk.tokenize.html)) that helps to clean up HTML tags and to respect/normalize emojis.\n",
    "- We remove English stopwords and most punctuation marks, except a few that convey semantic meaning.\n",
    "- Originally this used stemming, but we can also leverage lemmatization from NLTK at a very small cost, and it should in theory offer better quality results.\n",
    "- Any hashtag that looks like a word (e.g. `#angry`) has the initial `#` removed, since they normally carry regular meaning.\n",
    "- All URLs are replaced by `xxurl`.\n",
    "- All numbers ar replaced by `xxnum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "REGEX_URL = re.compile(r'https?://|www.')\n",
    "REGEX_NUM = re.compile(r'[0-9.-]?[0-9][0-9.-]?')\n",
    "\n",
    "TOKEN_URL = 'xxurl'\n",
    "TOKEN_NUM = 'xxnum'\n",
    "\n",
    "STOPWORDS_EN = set(stopwords.words('english') + [\"i've\"])\n",
    "STOP_PUNCT = set('.\"\\'&‚Äù‚Äú‚Äô,:;/*()[]{}@#')\n",
    "\n",
    "def normalize_token(token):\n",
    "    for regex, marker in [(REGEX_URL, TOKEN_URL), (REGEX_NUM, TOKEN_NUM)]:\n",
    "        if re.match(regex, token):\n",
    "            return marker\n",
    "    return token\n",
    "\n",
    "def get_wordnet_pos(pos):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos[0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def normalize_text(text, remove_stopwords=True, use_lemmatizer=False, remove_prefixes=True):\n",
    "    tokenizer = TweetTokenizer(preserve_case=False)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def is_stop_token(t):\n",
    "        return len(t) == 0 or t in STOP_PUNCT or remove_stopwords and t in STOPWORDS_EN\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # if the first token is a handler, it's normally irrelevant\n",
    "    if tokens[0].startswith('@'):\n",
    "        tokens.pop(0)\n",
    "\n",
    "    ntokens = []\n",
    "    \n",
    "    # STEP 1: cleanup, formatting\n",
    "    for token in tokens:\n",
    "        ntoken = normalize_token(token)\n",
    "        \n",
    "        if remove_prefixes and any(token.startswith(c) for c in ['@', '#']):\n",
    "            ntoken = ntoken[1:]\n",
    "        if not use_lemmatizer and is_stop_token(ntoken):\n",
    "            continue\n",
    "\n",
    "        ntokens.append(ntoken)\n",
    "        \n",
    "    if not use_lemmatizer:\n",
    "        return ' '.join(ntokens)\n",
    "    \n",
    "    ltokens = []\n",
    "    \n",
    "    # STEP 2: NLP tagging\n",
    "    pos_tags = nltk.pos_tag(ntokens)\n",
    "\n",
    "    # STEP 3: \"semantic\" cleaning\n",
    "    for token, pos in pos_tags:\n",
    "        if is_stop_token(token):\n",
    "            continue\n",
    "        if pos == 'CD':\n",
    "            ltoken = TOKEN_NUM\n",
    "        else:\n",
    "            ltoken = lemmatizer.lemmatize(token, get_wordnet_pos(pos))\n",
    "        ltokens.append(ltoken)\n",
    "           \n",
    "    return ' '.join(ltokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTRAL: @VirginAmerica What @dhepburn said.\n",
      ">> dhepburn said\n",
      "\n",
      "POSITIVE: @VirginAmerica plus you've added commercials to the experience... tacky.\n",
      ">> plus added commercials experience ... tacky\n",
      "\n",
      "NEUTRAL: @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
      ">> today ... must mean need take another trip !\n",
      "\n",
      "NEGATIVE: @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
      ">> really aggressive blast obnoxious entertainment guests faces little recourse\n",
      "\n",
      "NEGATIVE: @VirginAmerica and it's a really big bad thing about it\n",
      ">> really big bad thing\n",
      "\n",
      "NEGATIVE: @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA\n",
      ">> seriously would pay $ xxnum flight seats playing really bad thing flying va\n",
      "\n",
      "POSITIVE: @VirginAmerica yes, nearly every time I fly VX this ‚Äúear worm‚Äù won‚Äôt go away :)\n",
      ">> yes nearly every time fly vx ear worm go away :)\n",
      "\n",
      "NEUTRAL: @VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP\n",
      ">> really missed prime opportunity men without hats parody xxurl\n",
      "\n",
      "POSITIVE: @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D\n",
      ">> well ‚Ä¶ ! :-D\n",
      "\n",
      "POSITIVE: @VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\n",
      ">> amazing arrived hour early good\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_normalization(_df):\n",
    "    for i, row in _df.iterrows():\n",
    "        print(row.sentiment.upper() + \": \" + row.text + '\\n>> ' + normalize_text(row.text) + '\\n')\n",
    "\n",
    "show_normalization(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we add a new column to the dataset with the normalized texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dhepburn said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience ... tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>today ... must mean need take another trip !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay $ xxnum flight seats playi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>really missed prime opportunity men without ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D</td>\n",
       "      <td>positive</td>\n",
       "      <td>well ‚Ä¶ ! :-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>amazing arrived hour early good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>know suicide second leading cause death among ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>&lt;3 pretty graphics much better minimal iconogr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>positive</td>\n",
       "      <td>great deal ! already thinking xxnum trip austr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>virginmedia i'm flying fabulous seductive skie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>positive</td>\n",
       "      <td>thanks !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>negative</td>\n",
       "      <td>sfo-pdx schedule still mia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>excited first cross country flight lax mco hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>negative</td>\n",
       "      <td>flew nyc sfo last week fully sit seat due two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç</td>\n",
       "      <td>positive</td>\n",
       "      <td>‚ù§ Ô∏è flying virginamerica ‚ò∫ Ô∏è üëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>positive</td>\n",
       "      <td>know would amazingly awesome ? bos-fll please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@VirginAmerica why are your first fares in May...</td>\n",
       "      <td>negative</td>\n",
       "      <td>first fares may three times carriers seats ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love graphic xxurl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@VirginAmerica I love the hipster innovation. ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love hipster innovation feel good brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@VirginAmerica will you be making BOS&amp;gt;LAS n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>making bos &gt; las non stop permanently anytime ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@VirginAmerica you guys messed up my seating.....</td>\n",
       "      <td>negative</td>\n",
       "      <td>guys messed seating .. reserved seating friend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@VirginAmerica status match program.  I applie...</td>\n",
       "      <td>negative</td>\n",
       "      <td>status match program applied three weeks calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@VirginAmerica What happened 2 ur vegan food o...</td>\n",
       "      <td>negative</td>\n",
       "      <td>happened xxnum ur vegan food options ? ! least...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@VirginAmerica do you miss me? Don't worry we'...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>miss ? worry we'll together soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@VirginAmerica amazing to me that we can't get...</td>\n",
       "      <td>negative</td>\n",
       "      <td>amazing can't get cold air vents vx358 noair w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@VirginAmerica LAX to EWR - Middle seat on a r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>lax ewr - middle seat red eye noob maneuver se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  \\\n",
       "0                 @VirginAmerica What @dhepburn said.   neutral   \n",
       "1   @VirginAmerica plus you've added commercials t...  positive   \n",
       "2   @VirginAmerica I didn't today... Must mean I n...   neutral   \n",
       "3   @VirginAmerica it's really aggressive to blast...  negative   \n",
       "4   @VirginAmerica and it's a really big bad thing...  negative   \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...  negative   \n",
       "6   @VirginAmerica yes, nearly every time I fly VX...  positive   \n",
       "7   @VirginAmerica Really missed a prime opportuni...   neutral   \n",
       "8     @virginamerica Well, I didn't‚Ä¶but NOW I DO! :-D  positive   \n",
       "9   @VirginAmerica it was amazing, and arrived an ...  positive   \n",
       "10  @VirginAmerica did you know that suicide is th...   neutral   \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...  positive   \n",
       "12  @VirginAmerica This is such a great deal! Alre...  positive   \n",
       "13  @VirginAmerica @virginmedia I'm flying your #f...  positive   \n",
       "14                             @VirginAmerica Thanks!  positive   \n",
       "15      @VirginAmerica SFO-PDX schedule is still MIA.  negative   \n",
       "16  @VirginAmerica So excited for my first cross c...  positive   \n",
       "17  @VirginAmerica  I flew from NYC to SFO last we...  negative   \n",
       "18                    I ‚ù§Ô∏è flying @VirginAmerica. ‚ò∫Ô∏èüëç  positive   \n",
       "19  @VirginAmerica you know what would be amazingl...  positive   \n",
       "20  @VirginAmerica why are your first fares in May...  negative   \n",
       "21  @VirginAmerica I love this graphic. http://t.c...  positive   \n",
       "22  @VirginAmerica I love the hipster innovation. ...  positive   \n",
       "23  @VirginAmerica will you be making BOS&gt;LAS n...   neutral   \n",
       "24  @VirginAmerica you guys messed up my seating.....  negative   \n",
       "25  @VirginAmerica status match program.  I applie...  negative   \n",
       "26  @VirginAmerica What happened 2 ur vegan food o...  negative   \n",
       "27  @VirginAmerica do you miss me? Don't worry we'...   neutral   \n",
       "28  @VirginAmerica amazing to me that we can't get...  negative   \n",
       "29  @VirginAmerica LAX to EWR - Middle seat on a r...   neutral   \n",
       "\n",
       "                                            norm_text  \n",
       "0                                       dhepburn said  \n",
       "1         plus added commercials experience ... tacky  \n",
       "2        today ... must mean need take another trip !  \n",
       "3   really aggressive blast obnoxious entertainmen...  \n",
       "4                                really big bad thing  \n",
       "5   seriously would pay $ xxnum flight seats playi...  \n",
       "6    yes nearly every time fly vx ear worm go away :)  \n",
       "7   really missed prime opportunity men without ha...  \n",
       "8                                        well ‚Ä¶ ! :-D  \n",
       "9                     amazing arrived hour early good  \n",
       "10  know suicide second leading cause death among ...  \n",
       "11  <3 pretty graphics much better minimal iconogr...  \n",
       "12  great deal ! already thinking xxnum trip austr...  \n",
       "13  virginmedia i'm flying fabulous seductive skie...  \n",
       "14                                           thanks !  \n",
       "15                         sfo-pdx schedule still mia  \n",
       "16  excited first cross country flight lax mco hea...  \n",
       "17  flew nyc sfo last week fully sit seat due two ...  \n",
       "18                     ‚ù§ Ô∏è flying virginamerica ‚ò∫ Ô∏è üëç  \n",
       "19  know would amazingly awesome ? bos-fll please ...  \n",
       "20  first fares may three times carriers seats ava...  \n",
       "21                                 love graphic xxurl  \n",
       "22            love hipster innovation feel good brand  \n",
       "23  making bos > las non stop permanently anytime ...  \n",
       "24  guys messed seating .. reserved seating friend...  \n",
       "25  status match program applied three weeks calle...  \n",
       "26  happened xxnum ur vegan food options ? ! least...  \n",
       "27                   miss ? worry we'll together soon  \n",
       "28  amazing can't get cold air vents vx358 noair w...  \n",
       "29  lax ewr - middle seat red eye noob maneuver se...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply normalization to ALL text\n",
    "df['norm_text'] = df.text.apply(normalize_text)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11541, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience ... tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay $ xxnum flight seats playi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away :)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "1  @VirginAmerica plus you've added commercials t...  positive   \n",
       "3  @VirginAmerica it's really aggressive to blast...  negative   \n",
       "4  @VirginAmerica and it's a really big bad thing...  negative   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...  negative   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...  positive   \n",
       "\n",
       "                                           norm_text  \n",
       "1        plus added commercials experience ... tacky  \n",
       "3  really aggressive blast obnoxious entertainmen...  \n",
       "4                               really big bad thing  \n",
       "5  seriously would pay $ xxnum flight seats playi...  \n",
       "6   yes nearly every time fly vx ear worm go away :)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary = df[df.sentiment != 'neutral']\n",
    "print(df_binary.shape)\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 7732; test: 3809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_test, label_train, label_test = train_test_split(df_binary['norm_text'], df_binary['sentiment'], test_size=0.33, random_state=0)\n",
    "\n",
    "print(\"Training: %d; test: %d\" % (len(text_train), len(text_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (key, train score, test score)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomian Naive Bayes using counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "\n",
    "y_train = [LABELS[l] for l in label_train]\n",
    "y_test = [LABELS[l] for l in label_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counter = CountVectorizer()\n",
    "X_train = counter.fit_transform(text_train)\n",
    "X_test = counter.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7732, 8678)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb_multi_counts', 0.9434816347646146, 0.902861643475978)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "result = ('nb_multi_counts', score_train, score_test)\n",
    "results.append(result)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB using TF-IDF, direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7732, 8469)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "v_train = vectorizer.fit_transform(text_train)\n",
    "v_test = vectorizer.transform(text_test)\n",
    "\n",
    "X_train = v_train.toarray()\n",
    "X_test = v_test.toarray()\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb_gaussian_tfidf', 0.8616140713916193, 0.7122604358099238)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "result = ('nb_gaussian_tfidf', score_train, score_test)\n",
    "results.append(result)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB using TF-IDF and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7732, 846)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(v_train, y_train)\n",
    "vs_train = selector.transform(v_train)\n",
    "vs_test  = selector.transform(v_test)\n",
    "\n",
    "X_train = vs_train.toarray()\n",
    "X_test = vs_test.toarray()\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nb_gaussian_tfidf_feature_sel', 0.874159337816865, 0.8112365450249409)\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "result = ('nb_gaussian_tfidf_feature_sel', score_train, score_test)\n",
    "results.append(result)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with kernel=rbf, C=1000.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "# we try different values of C and kernel\n",
    "kernels = ['linear', 'rbf']\n",
    "Cs = [1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "svm_results = []\n",
    "\n",
    "for kernel in ['rbf']: # kernels:\n",
    "    for cc in [1000.0]: # Cs:\n",
    "        print('Trying with kernel=%s, C=%f' % (kernel, cc))        \n",
    "        clf = SVC(kernel=kernel, C=cc, gamma='auto') # setting gamma=auto to avoid warning\n",
    "        t0 = time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        t1 = time()\n",
    "        score_train = clf.score(X_train, y_train)\n",
    "        score_test = clf.score(X_test, y_test)\n",
    "        t2 = time()\n",
    "        # (kernel, c, train score, test score, train time, score time)\n",
    "        svm_results.append((kernel, cc, score_train, score_test, t1 - t0, t2 - t1))\n",
    "        \n",
    "        result = ('svc_%s_c_%f' % (kernel, cc), score_train, score_test)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>time_train</th>\n",
       "      <th>time_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.935334</td>\n",
       "      <td>0.909163</td>\n",
       "      <td>22.175892</td>\n",
       "      <td>25.897262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  kernel       C  score_train  score_test  time_train  time_score\n",
       "0    rbf  1000.0     0.935334    0.909163   22.175892   25.897262"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_df = pd.DataFrame(svm_results, columns=['kernel', 'C', 'score_train', 'score_test', 'time_train', 'time_score'])\n",
    "svc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dtree', 0.9489136057941024, 0.8747702809136256)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "score_train = clf.score(X_train, y_train)\n",
    "score_test = clf.score(X_test, y_test)\n",
    "\n",
    "result = ('dtree', score_train, score_test)\n",
    "results.append(result)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes about pre-processing:\n",
    "- stemming did not seem to help\n",
    "- in fact, lemmatization using POS tags ended up in _slightly worse_ results that just simple normalization\n",
    "- the exception is the Decision Tree, it actually got better with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nb_multi_counts</td>\n",
       "      <td>0.943482</td>\n",
       "      <td>0.902862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nb_gaussian_tfidf</td>\n",
       "      <td>0.861614</td>\n",
       "      <td>0.712260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb_gaussian_tfidf_feature_sel</td>\n",
       "      <td>0.874159</td>\n",
       "      <td>0.811237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svc_rbf_c_1000.000000</td>\n",
       "      <td>0.935334</td>\n",
       "      <td>0.909163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dtree</td>\n",
       "      <td>0.948914</td>\n",
       "      <td>0.874770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          method  score_train  score_test\n",
       "0                nb_multi_counts     0.943482    0.902862\n",
       "1              nb_gaussian_tfidf     0.861614    0.712260\n",
       "2  nb_gaussian_tfidf_feature_sel     0.874159    0.811237\n",
       "3          svc_rbf_c_1000.000000     0.935334    0.909163\n",
       "4                          dtree     0.948914    0.874770"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['method', 'score_train', 'score_test'])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
