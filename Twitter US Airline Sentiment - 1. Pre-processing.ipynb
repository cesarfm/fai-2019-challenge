{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SIZE: (14640, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                @VirginAmerica What @dhepburn said.   neutral\n",
       "1  @VirginAmerica plus you've added commercials t...  positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...   neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...  negative\n",
       "4  @VirginAmerica and it's a really big bad thing...  negative"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from the CSV file\n",
    "INPUT_PATH = '../twitter-airline-sentiment/Tweets.csv'\n",
    "raw_data = pd.read_csv(INPUT_PATH, header=0)\n",
    "\n",
    "df = raw_data.copy()[['text', 'airline_sentiment']]\n",
    "df = df.rename(columns={'airline_sentiment': 'sentiment'})\n",
    "\n",
    "print(\"DATA SIZE: \" + str(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>9178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>3099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text\n",
       "sentiment      \n",
       "negative   9178\n",
       "neutral    3099\n",
       "positive   2363"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get class counts\n",
    "class_counts = df.groupby('sentiment').count()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts.text.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@united', 3893),\n",
       " ('@usairways', 2998),\n",
       " ('@americanair', 2961),\n",
       " ('@southwestair', 2458),\n",
       " ('@jetblue', 2248),\n",
       " ('@virginamerica', 518),\n",
       " ('@delta', 68),\n",
       " ('@imaginedragons', 45),\n",
       " ('@phlairport', 20),\n",
       " ('@dfwairport', 17),\n",
       " ('@wsj', 13),\n",
       " ('@ladygaga', 12),\n",
       " ('@carrieunderwood', 12),\n",
       " ('@fortunemagazine', 12),\n",
       " ('@love_dragonss', 10),\n",
       " ('@virginatlantic', 9),\n",
       " ('@flytpa', 9),\n",
       " ('@cowboycerrone', 9),\n",
       " ('@staralliance', 8),\n",
       " ('@gg8929', 8),\n",
       " ('@spiritairlines', 8),\n",
       " ('@velourlive', 8),\n",
       " ('@aircanada', 7),\n",
       " ('@dulles_airport', 6),\n",
       " ('@fly2ohare', 6),\n",
       " ('@cnn', 6),\n",
       " ('@bostonlogan', 6),\n",
       " ('@triflight', 6),\n",
       " ('@nytimes', 5),\n",
       " ('@flylaxairport', 5),\n",
       " ('@dallaslovefield', 5),\n",
       " ('@tsa', 5),\n",
       " ('@annricord', 5),\n",
       " ('@expedia', 5),\n",
       " ('@silverairways', 4),\n",
       " ('@southwest', 4),\n",
       " ('@deltaassist', 4),\n",
       " ('@ntrustopen', 4),\n",
       " ('@perfectomobile', 4),\n",
       " ('@british_airways', 4),\n",
       " ('@ny_njairports', 4),\n",
       " ('@mco', 4),\n",
       " ('@kylejudah', 4),\n",
       " ('@jayvig', 4),\n",
       " ('@askpaypal', 4),\n",
       " ('@derekc21', 4),\n",
       " ('@faanews', 3),\n",
       " ('@kciairport', 3),\n",
       " ('@capa_aviation', 3),\n",
       " ('@gma', 3),\n",
       " ('@thenationaluae', 3),\n",
       " ('@austinairport', 3),\n",
       " ('@usatoday', 3),\n",
       " ('@jms2802', 3),\n",
       " ('@rikrik__', 3),\n",
       " ('@flysfo', 3),\n",
       " ('@comcast', 3),\n",
       " ('@airlinegeeks', 3),\n",
       " ('@jedediahbila', 3),\n",
       " ('@iah', 3),\n",
       " ('@heathrowairport', 3),\n",
       " ('@directtv', 3),\n",
       " ('@phxskyharbor', 3),\n",
       " ('@lasairport', 3),\n",
       " ('@aarp', 3),\n",
       " ('@bwi', 3),\n",
       " ('@theellenshow', 3),\n",
       " ('@fly_nashville', 3),\n",
       " ('@bwi_airport', 3),\n",
       " ('@tatianaking', 3),\n",
       " ('@thewayoftheid', 3),\n",
       " ('@wmcactionnews5', 3),\n",
       " ('@amybruni', 3),\n",
       " ('@abcnetwork', 3),\n",
       " ('@airbus', 3),\n",
       " ('@zkatcher', 3),\n",
       " ('@ellahenderson', 3),\n",
       " ('@vincenzolandino', 3),\n",
       " ('@roxydigital', 3),\n",
       " ('@beamske', 3),\n",
       " ('@jtrexsocial', 3),\n",
       " ('@sweetingr', 3),\n",
       " ('@jack_kairys', 3),\n",
       " ('@latimes', 3),\n",
       " ('@chicagotribune', 3),\n",
       " ('@cnnbrk', 3),\n",
       " ('@dallas_news', 2),\n",
       " ('@gopro', 2),\n",
       " ('@freyabevan_fund', 2),\n",
       " ('@jezziegoldz', 2),\n",
       " ('@cheertymedad', 2),\n",
       " ('@flypdx', 2),\n",
       " ('@flyyow', 2),\n",
       " ('@mandarinjourney', 2),\n",
       " ('@momsgoodeats', 2),\n",
       " ('@flysaa', 2),\n",
       " ('@unfriendly', 2),\n",
       " ('@campilley', 2),\n",
       " ('@denairport', 2),\n",
       " ('@fioretti2ndward', 2),\n",
       " ('@garcia4chicago', 2),\n",
       " ('@parachuteguy', 2),\n",
       " ('@cnnmoney', 2),\n",
       " ('@foxnews', 2),\n",
       " ('@airnzusa', 2),\n",
       " ('@boeingairplanes', 2),\n",
       " ('@danahajek', 2),\n",
       " ('@battierccipuppy', 2),\n",
       " ('@embraersa', 2),\n",
       " ('@unitedappeals', 2),\n",
       " ('@jenniferwalshpr', 2),\n",
       " ('@iamtedking', 2),\n",
       " ('@loganairports', 2),\n",
       " ('@helacohlc', 2),\n",
       " ('@laurasbrown5', 2),\n",
       " ('@pgatour', 2),\n",
       " ('@alaskaair', 2),\n",
       " ('@gogo', 2),\n",
       " ('@fly2midway', 2),\n",
       " ('@theacademy', 2),\n",
       " ('@jimcramer', 2),\n",
       " ('@poteettj', 2),\n",
       " ('@tmadcle', 2),\n",
       " ('@dcoadavon', 2),\n",
       " ('@portcolumbuscmh', 2),\n",
       " ('@dultch97', 2),\n",
       " ('@southwestverity', 2),\n",
       " ('@nascar', 2),\n",
       " ('@michaelbcoleman', 2),\n",
       " ('@sammi_jon3s', 2),\n",
       " ('@hayleymad', 2),\n",
       " ('@thirty_lives', 2),\n",
       " ('@internjohnradio', 2),\n",
       " ('@mrerickv', 2),\n",
       " ('@beatsmusic', 2),\n",
       " ('@karajusto', 2),\n",
       " ('@vinylvegas', 2),\n",
       " ('@jetbluecheeps', 2),\n",
       " ('@natca', 2),\n",
       " ('@maatkare67', 2),\n",
       " ('@brandssayingbae', 2),\n",
       " ('@martysg', 2),\n",
       " ('@shannonwoodward', 2),\n",
       " ('@msbgu', 2),\n",
       " ('@2littlebirds', 2),\n",
       " ('@nhlonnbcsports', 2),\n",
       " ('@paulgordonbrown', 2),\n",
       " ('@thevdt', 2),\n",
       " ('@anku', 2),\n",
       " ('@ninadavuluri', 2),\n",
       " ('@bretharold', 2),\n",
       " ('@pattonoswalt', 2),\n",
       " ('@warriors', 2),\n",
       " ('@j_beatz247', 2),\n",
       " ('@professorpaul15', 2),\n",
       " ('@phd_mama_', 2),\n",
       " ('@chronicleherald', 2),\n",
       " ('@usair', 2),\n",
       " ('@dca', 2),\n",
       " ('@americanairlines', 2),\n",
       " ('@claudoakeshott', 2),\n",
       " ('@josephtreis', 2),\n",
       " ('@nburnside26', 2),\n",
       " ('@sb5551', 2),\n",
       " ('@jabevan221', 2),\n",
       " ('@reagan_airport', 2),\n",
       " ('@obj_3', 2),\n",
       " ('@kentuckymbb', 2),\n",
       " ('@franchise02', 2),\n",
       " ('@stephenrodrick', 2),\n",
       " ('@nrhodes85', 2),\n",
       " ('@annettenaif', 2),\n",
       " ('@andrew_wasila', 2),\n",
       " ('@pbpinftworth', 2),\n",
       " ('@robertdwyer', 2),\n",
       " ('@clarkey_19', 2),\n",
       " ('@itunesmusic', 2),\n",
       " ('@beantownmatty', 2),\n",
       " ('@lpalumbo', 2),\n",
       " ('@laguardiaair', 2),\n",
       " ('@souljacoy', 2),\n",
       " ('@superyan', 2),\n",
       " ('@chasefoster', 2),\n",
       " ('@cvgairport', 2),\n",
       " ('@nrosenb1', 2),\n",
       " ('@rizzilient', 2),\n",
       " ('@maryella_green', 2),\n",
       " ('@justynmoro', 2),\n",
       " ('@ggreenwald', 2),\n",
       " ('@robinreda', 2),\n",
       " ('@slcairport', 2),\n",
       " ('@sa_craig', 2),\n",
       " ('@travisamex', 2),\n",
       " ('@dhepburn', 1),\n",
       " ('@australia', 1),\n",
       " ('@virginmedia', 1),\n",
       " ('@pacificbiznews', 1),\n",
       " ('@freddieawards', 1),\n",
       " ('@travelzoo', 1),\n",
       " ('@fidifamilies', 1),\n",
       " ('@chrysichrysic', 1),\n",
       " ('@reallytallchris', 1),\n",
       " ('@sfo', 1),\n",
       " ('@waltdisneyworld', 1),\n",
       " ('@jessicajaymes', 1),\n",
       " ('@ttinac11', 1),\n",
       " ('@asarco_es_ar', 1),\n",
       " ('@love', 1),\n",
       " ('@fastcompany', 1),\n",
       " ('@newsvp', 1),\n",
       " ('@iol', 1),\n",
       " ('@lizautter', 1),\n",
       " ('@renttherunway', 1),\n",
       " ('@atwonline', 1),\n",
       " ('@reuters', 1),\n",
       " ('@madbee95', 1),\n",
       " ('@ssal', 1),\n",
       " ('@shrinerack', 1),\n",
       " ('@suuperg', 1),\n",
       " ('@visa', 1),\n",
       " ('@giannilee', 1),\n",
       " ('@skift', 1),\n",
       " ('@karinslee', 1),\n",
       " ('@tinder', 1),\n",
       " ('@fargoairport', 1),\n",
       " ('@starryeyes_dev_', 1),\n",
       " ('@jenniferdawnpro', 1),\n",
       " ('@highbuddyyy', 1),\n",
       " ('@aegeanairlines', 1),\n",
       " ('@_austrian', 1),\n",
       " ('@uctraveladvisor', 1),\n",
       " ('@getmeontop', 1),\n",
       " ('@verizonwireless', 1),\n",
       " ('@ccicanine', 1),\n",
       " ('@simonroesner', 1),\n",
       " ('@bbbne_sd_ks_ia', 1),\n",
       " ('@choosechicago', 1),\n",
       " ('@capeair', 1),\n",
       " ('@lindaswc', 1),\n",
       " ('@melaniespring', 1),\n",
       " ('@darquenloveli', 1),\n",
       " ('@tumitravel', 1),\n",
       " ('@luke_mcintosh68', 1),\n",
       " ('@3', 1),\n",
       " ('@pivotalcf', 1),\n",
       " ('@thehipmunk', 1),\n",
       " ('@mllovelace', 1),\n",
       " ('@renoairport', 1),\n",
       " ('@whitterbug', 1),\n",
       " ('@apollochplayers', 1),\n",
       " ('@goodenufmother', 1),\n",
       " ('@reebok', 1),\n",
       " ('@rockinwellness', 1),\n",
       " ('@dustyob', 1),\n",
       " ('@dfpietra', 1),\n",
       " ('@truu_tall', 1),\n",
       " ('@flyeia', 1),\n",
       " ('@imran_r44', 1),\n",
       " ('@keambleam', 1),\n",
       " ('@melissaafrancis', 1),\n",
       " ('@not', 1),\n",
       " ('@retailbagholder', 1),\n",
       " ('@ewr', 1),\n",
       " ('@seanmfmadden', 1),\n",
       " ('@peterstraubmma', 1),\n",
       " ('@jmercadomma', 1),\n",
       " ('@tonysimsmma', 1),\n",
       " ('@megzezzo', 1),\n",
       " ('@scotthroth', 1),\n",
       " ('@reagan', 1),\n",
       " ('@zrh_airport', 1),\n",
       " ('@airport_fra', 1),\n",
       " ('@showexpert', 1),\n",
       " ('@bdl', 1),\n",
       " ('@preboard', 1),\n",
       " ('@naia_miaa', 1),\n",
       " ('@ba_usa', 1),\n",
       " ('@ciscojimfrench', 1),\n",
       " ('@cobedien', 1),\n",
       " ('@cgjase', 1),\n",
       " ('@delongerry', 1),\n",
       " ('@reccewife', 1),\n",
       " ('@it', 1),\n",
       " ('@flightaware', 1),\n",
       " ('@baftz', 1),\n",
       " ('@fernheinig18', 1),\n",
       " ('@lpdstock', 1),\n",
       " ('@jeffsmisek', 1),\n",
       " ('@robertfor39', 1),\n",
       " ('@erieairport', 1),\n",
       " ('@yyz', 1),\n",
       " ('@rayja9', 1),\n",
       " ('@lsusoftball', 1),\n",
       " ('@lsuquinlanduhon', 1),\n",
       " ('@aerocivilcol', 1),\n",
       " ('@lmuschel', 1),\n",
       " ('@goosebayairport', 1),\n",
       " ('@czamkoff', 1),\n",
       " ('@tiffanyandco', 1),\n",
       " ('@theairhelper', 1),\n",
       " ('@4geiger', 1),\n",
       " ('@auciello', 1),\n",
       " ('@wamo66', 1),\n",
       " ('@suntoshi', 1),\n",
       " ('@maxabrahms', 1),\n",
       " ('@thisiscoach', 1),\n",
       " ('@abc11_wtvd', 1),\n",
       " ('@aggiemensgolf', 1),\n",
       " ('@msnbc', 1),\n",
       " ('@ehsanismpowered', 1),\n",
       " ('@stevelord212', 1),\n",
       " ('@americanone', 1),\n",
       " ('@nathankillam', 1),\n",
       " ('@dad_or_alive', 1),\n",
       " ('@xfinity', 1),\n",
       " ('@10am', 1),\n",
       " ('@continentalair1', 1),\n",
       " ('@panynj', 1),\n",
       " ('@froschtravel', 1),\n",
       " ('@baldordash', 1),\n",
       " ('@jimtrotter_nfl', 1),\n",
       " ('@bhx_official', 1),\n",
       " ('@addair', 1),\n",
       " ('@paigeworthy', 1),\n",
       " ('@kleankanteen', 1),\n",
       " ('@scvpools', 1),\n",
       " ('@airlines', 1),\n",
       " ('@leigh_emery', 1),\n",
       " ('@sydneyairport', 1),\n",
       " ('@iflyoakland', 1),\n",
       " ('@skywest', 1),\n",
       " ('@d_goodspeed', 1),\n",
       " ('@bobwesson', 1),\n",
       " ('@ant_kneee', 1),\n",
       " ('@robthecameraman', 1),\n",
       " ('@airfarewatchdog', 1),\n",
       " ('@44stocker', 1),\n",
       " ('@tpallini', 1),\n",
       " ('@lruns4cupcakes', 1),\n",
       " ('@clarkhoward', 1),\n",
       " ('@upgrd', 1),\n",
       " ('@kathrynsotelo', 1),\n",
       " ('@belfastairport', 1),\n",
       " ('@adam_karren', 1),\n",
       " ('@zj76', 1),\n",
       " ('@abigailedge', 1),\n",
       " ('@hemispheresmag', 1),\n",
       " ('@dan_roam', 1),\n",
       " ('@robbogart', 1),\n",
       " ('@5', 1),\n",
       " ('@dmb41shows', 1),\n",
       " ('@hiltonworldwide', 1),\n",
       " ('@caravannyc', 1),\n",
       " ('@maysvillenyc', 1),\n",
       " ('@airlineguys', 1),\n",
       " ('@robcnyc', 1),\n",
       " ('@sonyasloanmd', 1),\n",
       " ('@bwood', 1),\n",
       " ('@ups', 1),\n",
       " ('@fedex', 1),\n",
       " ('@estellevw', 1),\n",
       " ('@therealaviation', 1),\n",
       " ('@etihad', 1),\n",
       " ('@hotelstonight', 1),\n",
       " ('@startingbloc', 1),\n",
       " ('@unitedflyerhd', 1),\n",
       " ('@united_airline', 1),\n",
       " ('@b787fans', 1),\n",
       " ('@christinebpc', 1),\n",
       " ('@vusa_australia', 1),\n",
       " ('@skiplagged', 1),\n",
       " ('@itsaaronchriz', 1),\n",
       " ('@parryaftab', 1),\n",
       " ('@qlyss8', 1),\n",
       " ('@burningman', 1),\n",
       " ('@virgin', 1),\n",
       " ('@silverairwsys', 1),\n",
       " ('@westjet', 1),\n",
       " ('@shulemstern', 1),\n",
       " ('@ftlauderdalesun', 1),\n",
       " ('@orlandosentinel', 1),\n",
       " ('@webbernaturals', 1),\n",
       " ('@cbcallinaday', 1),\n",
       " ('@cbcnews', 1),\n",
       " ('@harris', 1),\n",
       " ('@ansleyhutson', 1),\n",
       " ('@emily_donneiiy', 1),\n",
       " ('@unitedairlines', 1),\n",
       " ('@directv', 1),\n",
       " ('@dadboner', 1),\n",
       " ('@superben', 1),\n",
       " ('@el_ingeniero', 1),\n",
       " ('@huffpostbiz', 1),\n",
       " ('@mrandyep', 1),\n",
       " ('@rajuchinthala', 1),\n",
       " ('@flyana_official', 1),\n",
       " ('@casleah', 1),\n",
       " ('@jsumiyasu', 1),\n",
       " ('@flyfrontier', 1),\n",
       " ('@heavenlychc9', 1),\n",
       " ('@9news', 1),\n",
       " ('@smiles1307', 1),\n",
       " ('@marriott', 1),\n",
       " ('@intuit', 1),\n",
       " ('@jhamilton2007', 1),\n",
       " ('@kevinswan_', 1),\n",
       " ('@alstdi', 1),\n",
       " ('@a_life_story_', 1),\n",
       " ('@c_istudios', 1),\n",
       " ('@tmobile', 1),\n",
       " ('@taylorlumsden', 1),\n",
       " ('@very', 1),\n",
       " ('@fuyukaidesuyo', 1),\n",
       " ('@comclassic', 1),\n",
       " ('@sadie4406', 1),\n",
       " ('@fox8news', 1),\n",
       " ('@kristi_capel', 1),\n",
       " ('@hdsportsguy', 1),\n",
       " ('@rncahill', 1),\n",
       " ('@lukewyckoff', 1),\n",
       " ('@matthewebel', 1),\n",
       " ('@coachgs', 1),\n",
       " ('@clinicpolly', 1),\n",
       " ('@furryfiesta', 1),\n",
       " ('@nelsjeff', 1),\n",
       " ('@kkwhb', 1),\n",
       " ('@daysinn', 1),\n",
       " ('@jparkermastin', 1),\n",
       " ('@specialolympics', 1),\n",
       " ('@allegiantair', 1),\n",
       " ('@megelizabeth631', 1),\n",
       " ('@mitchellairport', 1),\n",
       " ('@danihampton', 1),\n",
       " ('@chicagomidway', 1),\n",
       " ('@business', 1),\n",
       " ('@jindalcmc', 1),\n",
       " ('@vitaminwater', 1),\n",
       " ('@leinenkugels', 1),\n",
       " ('@dosequis', 1),\n",
       " ('@fattire', 1),\n",
       " ('@callmestanley7', 1),\n",
       " ('@bgr1061', 1),\n",
       " ('@ryand2285', 1),\n",
       " ('@southwestoliver', 1),\n",
       " ('@cspkcats', 1),\n",
       " ('@kdepetro313', 1),\n",
       " ('@olive201', 1),\n",
       " ('@tifffyhuang', 1),\n",
       " ('@jasonwhitely', 1),\n",
       " ('@swagglikebean', 1),\n",
       " ('@sacintlairport', 1),\n",
       " ('@djq_kc', 1),\n",
       " ('@djimpact', 1),\n",
       " ('@julgood1', 1),\n",
       " ('@amin_aur', 1),\n",
       " ('@liveatfirefly', 1),\n",
       " ('@_defcon_', 1),\n",
       " ('@thetroubadour', 1),\n",
       " ('@disneyland', 1),\n",
       " ('@franks105', 1),\n",
       " ('@orangecounty', 1),\n",
       " ('@samoore10', 1),\n",
       " ('@ashevilleair', 1),\n",
       " ('@murraysawchuck', 1),\n",
       " ('@930', 1),\n",
       " ('@geekstiel', 1),\n",
       " ('@vindictive_tk', 1),\n",
       " ('@disupdates', 1),\n",
       " ('@amiltx3', 1),\n",
       " ('@pancho_joe', 1),\n",
       " ('@livvyports16', 1),\n",
       " ('@dresparkles', 1),\n",
       " ('@cbsbaltimore', 1),\n",
       " ('@uno_baseball', 1),\n",
       " ('@igotmonte', 1),\n",
       " ('@saianel', 1),\n",
       " ('@budget', 1),\n",
       " ('@brittanyobx11', 1),\n",
       " ('@dispatchalerts', 1),\n",
       " ('@jlittle100', 1),\n",
       " ('@luxclark', 1),\n",
       " ('@flightspots', 1),\n",
       " ('@tbuccherifrnc3e', 1),\n",
       " ('@timieyancey', 1),\n",
       " ('@bet', 1),\n",
       " ('@me', 1),\n",
       " ('@kaneshow', 1),\n",
       " ('@leeannhealey', 1),\n",
       " ('@taylormdowns', 1),\n",
       " ('@ubergizmo', 1),\n",
       " ('@brendanpshannon', 1),\n",
       " ('@kirkwoodtiger', 1),\n",
       " ('@saysorrychris', 1),\n",
       " ('@sagerooski', 1),\n",
       " ('@brianregancomic', 1),\n",
       " ('@deltapoints', 1),\n",
       " ('@smusportmgt', 1),\n",
       " ('@cakairport', 1),\n",
       " ('@courtsnod', 1),\n",
       " ('@hillaconlin', 1),\n",
       " ('@tinaisback', 1),\n",
       " ('@johnwayneair', 1),\n",
       " ('@travelportland', 1),\n",
       " ('@no_airport', 1),\n",
       " ('@poisonpill76', 1),\n",
       " ('@matt_e_boss', 1),\n",
       " ('@tomvh', 1),\n",
       " ('@annebevi', 1),\n",
       " ('@paulbev1', 1),\n",
       " ('@mikeabramson', 1),\n",
       " ('@cbssoxfan', 1),\n",
       " ('@paytontaylor129', 1),\n",
       " ('@bernhardtjh', 1),\n",
       " ('@notpghtimothy', 1),\n",
       " ('@gruber', 1),\n",
       " ('@challemann', 1),\n",
       " ('@twitter', 1),\n",
       " ('@sxsw', 1),\n",
       " ('@terrybrokebad', 1),\n",
       " ('@askamex', 1),\n",
       " ('@catfoodbeerglue', 1),\n",
       " ('@ruth_slobodin', 1),\n",
       " ('@eatgregeat', 1),\n",
       " ('@nokidhungry', 1),\n",
       " ('@foodnetwork', 1),\n",
       " ('@gopuregrenada', 1),\n",
       " ('@discovergrenada', 1),\n",
       " ('@caribbejan', 1),\n",
       " ('@islandexpert', 1),\n",
       " ('@jannasaurusrex', 1),\n",
       " ('@marinadomine', 1),\n",
       " ('@ericbradleypt', 1),\n",
       " ('@briansumers', 1),\n",
       " ('@datingrev', 1),\n",
       " ('@lbairport', 1),\n",
       " ('@longbeachcity', 1),\n",
       " ('@bucketobolts', 1),\n",
       " ('@weepysweetmonty', 1),\n",
       " ('@mrjustyn', 1),\n",
       " ('@s_myc88', 1),\n",
       " ('@bostongarden', 1),\n",
       " ('@hellobrittney_', 1),\n",
       " ('@courteroy', 1),\n",
       " ('@alynewton', 1),\n",
       " ('@universalorl', 1),\n",
       " ('@jeff_hofmann', 1),\n",
       " ('@denisejtaylor', 1),\n",
       " ('@laurieameacham', 1),\n",
       " ('@nyjets', 1),\n",
       " ('@emaleesugano', 1),\n",
       " ('@zakkohane', 1),\n",
       " ('@cosmopolitan', 1),\n",
       " ('@julesdameron', 1),\n",
       " ('@abc', 1),\n",
       " ('@medium', 1),\n",
       " ('@finleybklyncfs', 1),\n",
       " ('@uschamber', 1),\n",
       " ('@hawaiianair', 1),\n",
       " ('@12am', 1),\n",
       " ('@airport', 1),\n",
       " ('@setorii', 1),\n",
       " ('@cookjaycook123', 1),\n",
       " ('@amagrino', 1),\n",
       " ('@fllairport', 1),\n",
       " ('@tfgreenairport', 1),\n",
       " ('@sylvie75015', 1),\n",
       " ('@mxo42', 1),\n",
       " ('@henrikwagner73', 1),\n",
       " ('@americanairbr', 1),\n",
       " ('@dgruber1700', 1),\n",
       " ('@maddie_flood', 1),\n",
       " ('@help_lindsey', 1),\n",
       " ('@l_burley11', 1),\n",
       " ('@heinekenusacorp', 1),\n",
       " ('@johnnosta', 1),\n",
       " ('@itslaloca', 1),\n",
       " ('@viraltech', 1),\n",
       " ('@usatodaytravel', 1),\n",
       " ('@redreserve', 1),\n",
       " ('@benjaminokeefe', 1),\n",
       " ('@tuftsenergyconf', 1),\n",
       " ('@zacks_com', 1),\n",
       " ('@ferrissalameh', 1),\n",
       " ('@dlewis2412', 1),\n",
       " ('@cavs', 1),\n",
       " ('@vainglorygame', 1),\n",
       " ('@markie_post', 1),\n",
       " ('@fitbit', 1),\n",
       " ('@hgeronemus', 1),\n",
       " ('@hanneslohmann', 1),\n",
       " ('@stacycrossb6', 1),\n",
       " ('@saharasams', 1),\n",
       " ('@jamaica', 1),\n",
       " ('@wikipearl', 1),\n",
       " ('@natprodexpo', 1),\n",
       " ('@wsjplus', 1),\n",
       " ('@walls29', 1),\n",
       " ('@samchampion', 1),\n",
       " ('@marketwatch', 1),\n",
       " ('@cflanagian', 1),\n",
       " ('@yaffasolin', 1),\n",
       " ('@kgonzales89', 1),\n",
       " ('@buffaloairport', 1),\n",
       " ('@lopezlaymari', 1),\n",
       " ('@airbusintheus', 1),\n",
       " ('@aruba_airport', 1),\n",
       " ('@peaches275', 1),\n",
       " ('@nhlbruins', 1),\n",
       " ('@saxonandparole', 1),\n",
       " ('@yeniettelswood', 1),\n",
       " ('@andrewbiga', 1),\n",
       " ('@codycleverly', 1),\n",
       " ('@heidimacey', 1),\n",
       " ('@motherpollock', 1),\n",
       " ('@rundisney', 1),\n",
       " ('@airlineadviser', 1),\n",
       " ('@kylecomer_', 1),\n",
       " ('@gripeo', 1),\n",
       " ('@t5sparrow', 1),\n",
       " ('@teamtreehouse', 1),\n",
       " ('@memgrizz', 1),\n",
       " ('@spurs', 1),\n",
       " ('@okcthunder', 1),\n",
       " ('@airlinequality', 1),\n",
       " ('@marieharf', 1),\n",
       " ('@pilyoc', 1),\n",
       " ('@usnavy', 1),\n",
       " ('@fare', 1),\n",
       " ('@lisapal', 1),\n",
       " ('@0xjared', 1),\n",
       " ('@cameron__roe', 1),\n",
       " ('@cayman_islands', 1),\n",
       " ('@cinnabon', 1),\n",
       " ('@drwinston001', 1),\n",
       " ('@philpete', 1),\n",
       " ('@_justdippin_', 1),\n",
       " ('@bloombergnews', 1),\n",
       " ('@kleinerin', 1),\n",
       " ('@leopolds_ic', 1),\n",
       " ('@mypompanobeach', 1),\n",
       " ('@analystdoc', 1),\n",
       " ('@citi', 1),\n",
       " ('@supertzar85', 1),\n",
       " ('@tinman2ironman', 1),\n",
       " ('@meggersrocks', 1),\n",
       " ('@hp', 1),\n",
       " ('@cbarrows', 1),\n",
       " ('@cinziannap', 1),\n",
       " ('@geekandahalf', 1),\n",
       " ('@pamgrout', 1),\n",
       " ('@sxu', 1),\n",
       " ('@vegecomgirl', 1),\n",
       " ('@nzherald', 1),\n",
       " ('@ashleykatherton', 1),\n",
       " ('@dmoukdarath', 1),\n",
       " ('@yorkshire2002', 1),\n",
       " ('@__rwg__', 1),\n",
       " ('@joyadventuremom', 1),\n",
       " ('@flyknoxville', 1),\n",
       " ('@philacarservice', 1),\n",
       " ('@mitchsunderland', 1),\n",
       " ('@vincesviews', 1),\n",
       " ('@gregm528', 1),\n",
       " ('@hhagerty', 1),\n",
       " ('@cbsnews', 1),\n",
       " ('@cltdouglas', 1),\n",
       " ('@marvinatorsb', 1),\n",
       " ('@av_duffy', 1),\n",
       " ('@jhughes1025', 1),\n",
       " ('@hutchinsjim', 1),\n",
       " ('@acnewsguy', 1),\n",
       " ('@americanairlnes', 1),\n",
       " ('@hegshmeg', 1),\n",
       " ('@pdquigley', 1),\n",
       " ('@landonschott', 1),\n",
       " ('@renhotels', 1),\n",
       " ('@marriottrewards', 1),\n",
       " ('@peterpiatetsky', 1),\n",
       " ('@were', 1),\n",
       " ('@down', 1),\n",
       " ('@longbeachairport', 1),\n",
       " ('@flyrepublicair', 1),\n",
       " ('@gregwallace66', 1),\n",
       " ('@truthh4', 1),\n",
       " ('@lgb', 1),\n",
       " ('@aurorabiz', 1),\n",
       " ('@usairwayscenter', 1),\n",
       " ('@cbsphilly', 1),\n",
       " ('@usaireays', 1),\n",
       " ('@barclaycardus', 1),\n",
       " ('@the_uso', 1),\n",
       " ('@wtop', 1),\n",
       " ('@bradley_airport', 1),\n",
       " ('@las', 1),\n",
       " ('@mrrenevendez', 1),\n",
       " ('@corybronze', 1),\n",
       " ('@thehaileytate', 1),\n",
       " ('@flightglobal', 1),\n",
       " ('@alfamilyoffour', 1),\n",
       " ('@msscottwg', 1),\n",
       " ('@nanceebing', 1),\n",
       " ('@brizzyberg27', 1),\n",
       " ('@41cgqueen', 1),\n",
       " ('@mia', 1),\n",
       " ('@kieranmahan', 1),\n",
       " ('@caterobbie', 1),\n",
       " ('@ch_mom', 1),\n",
       " ('@nm4agoodlife', 1),\n",
       " ('@_robprice', 1),\n",
       " ('@traveloneworld', 1),\n",
       " ('@rylietolbert15', 1),\n",
       " ('@usairwayssuck', 1),\n",
       " ('@timbennettg3', 1),\n",
       " ('@marccopely', 1),\n",
       " ('@shivadelrahim', 1),\n",
       " ('@prof_solutions', 1),\n",
       " ('@seanvrose', 1),\n",
       " ('@aumilo1', 1),\n",
       " ('@keithlaw', 1),\n",
       " ('@american', 1),\n",
       " ('@my', 1),\n",
       " ('@nationalairpor', 1),\n",
       " ('@upinairclaire', 1),\n",
       " ('@sarahpompei', 1),\n",
       " ('@andrewfallis', 1),\n",
       " ('@jdbwaffles', 1),\n",
       " ('@of', 1),\n",
       " ('@garywerk', 1),\n",
       " ('@alan_bledsoe', 1),\n",
       " ('@gastoncounty', 1),\n",
       " ('@albertbreer', 1),\n",
       " ('@cakendeath', 1),\n",
       " ('@hirasmusbidragi', 1),\n",
       " ('@dublinairport', 1),\n",
       " ('@loveloughneagh', 1),\n",
       " ('@cheapoair', 1),\n",
       " ('@allegianttravel', 1),\n",
       " ('@wallstslumlord', 1),\n",
       " ('@pkg49', 1),\n",
       " ('@marciaveronicaa', 1),\n",
       " ('@paypal', 1),\n",
       " ('@portlandjetport', 1),\n",
       " ('@drvrugby', 1),\n",
       " ('@samsonite', 1),\n",
       " ('@scm1133', 1),\n",
       " ('@bohnjai', 1),\n",
       " ('@phl', 1),\n",
       " ('@sdfairport', 1),\n",
       " ('@svllindia', 1),\n",
       " ('@forsyth_factor', 1),\n",
       " ('@dsearls', 1),\n",
       " ('@fispahani', 1),\n",
       " ('@husainhaqqani', 1),\n",
       " ('@noltnancy', 1),\n",
       " ('@erickofiejones', 1),\n",
       " ('@emilylyonss', 1),\n",
       " ('@satesq', 1),\n",
       " ('@ernie_vigil', 1),\n",
       " ('@bostonbbb', 1),\n",
       " ('@google', 1),\n",
       " ('@edreams_en', 1),\n",
       " ('@ods1819', 1),\n",
       " ('@mauererpower', 1),\n",
       " ('@cityandsand', 1),\n",
       " ('@dumas2ttg', 1),\n",
       " ('@iata', 1),\n",
       " ('@thefaaonline', 1),\n",
       " ('@jayfranceschi', 1),\n",
       " ('@slacksoft_uk', 1),\n",
       " ('@abc7newsbayarea', 1),\n",
       " ('@emxlyy', 1),\n",
       " ('@spiritairpr', 1),\n",
       " ('@chicagosmayor', 1),\n",
       " ('@djevolutionhd', 1),\n",
       " ('@gerri_elliott', 1),\n",
       " ('@megentripodi', 1),\n",
       " ('@jordnnicole7', 1),\n",
       " ('@dartmedia', 1),\n",
       " ('@suntimes', 1),\n",
       " ('@louprice13', 1),\n",
       " ('@aacustomerservice', 1),\n",
       " ('@thecandacesmith', 1),\n",
       " ('@krescate', 1),\n",
       " ('@contactcej', 1),\n",
       " ('@bbb_media', 1),\n",
       " ('@jokerunning', 1),\n",
       " ('@barrettkarabis', 1),\n",
       " ('@kanne822', 1),\n",
       " ('@elwoodblues77', 1),\n",
       " ('@jcolenc', 1),\n",
       " ('@maxfitgirl29', 1),\n",
       " ('@mattthomasnews', 1),\n",
       " ('@helsinkiairport', 1),\n",
       " ('@midoexhibition', 1),\n",
       " ('@edplotts', 1),\n",
       " ('@yourlocalnyer', 1),\n",
       " ('@tywinter', 1),\n",
       " ('@nbsnewsr', 1),\n",
       " ('@_lucy_may', 1),\n",
       " ('@starbucks', 1),\n",
       " ('@packermama1', 1),\n",
       " ('@cathaypacific', 1),\n",
       " ('@cathaypacificus', 1),\n",
       " ('@airsouthwest', 1),\n",
       " ('@rldelahunty', 1),\n",
       " ('@andyellwood', 1),\n",
       " ('@delk', 1),\n",
       " ('@meerikangas', 1),\n",
       " ('@hoagy10', 1),\n",
       " ('@amexserve', 1),\n",
       " ('@eleonora7', 1),\n",
       " ('@mallowfairy', 1),\n",
       " ('@c2next', 1),\n",
       " ('@murphyjulie', 1),\n",
       " ('@malhoit', 1),\n",
       " ('@mwangbickler', 1),\n",
       " ('@active_aly', 1),\n",
       " ('@usairwis', 1),\n",
       " ('@kaha58', 1),\n",
       " ('@emrey35', 1),\n",
       " ('@admiralsclub', 1),\n",
       " ('@nickcunningham1', 1),\n",
       " ('@loganex', 1),\n",
       " ('@emeyerson', 1),\n",
       " ('@nashinmypants', 1),\n",
       " ('@juliasinton948', 1),\n",
       " ('@arminrosen', 1),\n",
       " ('@bensonhenderson', 1),\n",
       " ('@dogbuckeye', 1),\n",
       " ('@lesliewolfson', 1),\n",
       " ('@nlrphoto', 1),\n",
       " ('@espn_coachmack', 1),\n",
       " ('@greyhoundbus', 1),\n",
       " ('@ti2469', 1),\n",
       " ('@duanenclark', 1),\n",
       " ('@vanessaannz', 1),\n",
       " ('@mo3tvida', 1),\n",
       " ('@dai_president', 1),\n",
       " ('@cinedrones', 1),\n",
       " ('@carlw1980', 1),\n",
       " ('@praywinn', 1),\n",
       " ('@priceline', 1),\n",
       " ('@jaynegelman', 1),\n",
       " ('@blacklist', 1),\n",
       " ('@heymynameissean', 1),\n",
       " ('@kconti44', 1),\n",
       " ('@jameswester', 1),\n",
       " ('@cjdjpdx', 1),\n",
       " ('@kaps12', 1),\n",
       " ('@rcm_oficial', 1),\n",
       " ('@cisnerosmedia', 1),\n",
       " ('@cyncyn661', 1),\n",
       " ('@patrichruben', 1),\n",
       " ('@cnbc', 1),\n",
       " ('@bloombergradio', 1),\n",
       " ('@manuel_c', 1),\n",
       " ('@ezemanalyst', 1),\n",
       " ('@sarahzou', 1),\n",
       " ('@jimdaytv', 1),\n",
       " ('@jfk', 1),\n",
       " ('@bershawnjackson', 1),\n",
       " ('@dawn_davis', 1),\n",
       " ('@dotnetnate', 1),\n",
       " ('@seguinej', 1),\n",
       " ('@sentierimelinda', 1),\n",
       " ('@tcunningham10', 1),\n",
       " ('@karabuxthomps', 1),\n",
       " ('@macario2', 1),\n",
       " ('@golfwithwoody', 1),\n",
       " ('@russellswriting', 1),\n",
       " ('@thenatek', 1),\n",
       " ('@cheerupdates', 1),\n",
       " ('@naomi_cooper', 1),\n",
       " ('@bdindallas', 1),\n",
       " ('@_emmaclifford', 1),\n",
       " ('@ejacqui', 1),\n",
       " ('@russelneiss', 1),\n",
       " ('@airtahitinui', 1),\n",
       " ('@sweetmel', 1),\n",
       " ('@caexhibitions', 1),\n",
       " ('@tennetexan', 1),\n",
       " ('@marxsterbcow', 1),\n",
       " ('@actingoutmgmnt', 1),\n",
       " ('@brewcrewfan8', 1),\n",
       " ('@yvonneokaka', 1),\n",
       " ('@shannonbloom', 1),\n",
       " ('@stone9956', 1),\n",
       " ('@jlhalldc', 1),\n",
       " ('@tilleymonsta', 1)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find the handlers\n",
    "from collections import Counter\n",
    "\n",
    "def get_text_sequence(_df):\n",
    "    return (row.text for _, row in _df.iterrows())\n",
    "\n",
    "def get_all_handlers(text_it):\n",
    "    handler_counts = Counter()\n",
    "\n",
    "    tokenizer = TweetTokenizer(preserve_case=False)\n",
    "    \n",
    "    for text in text_it:\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        handler_counts.update(t for t in tokens if len(t) > 1 and t.startswith('@'))\n",
    "\n",
    "    return handler_counts\n",
    "\n",
    "handler_counts = get_all_handlers(get_text_sequence(df))\n",
    "handler_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPROACH 1: Naive Bayes, all classes with full size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "REGEX_URL = re.compile(r'https?://|www.')\n",
    "#REGEX_HANDLE = re.compile(r'@\\w+')\n",
    "REGEX_NUM = re.compile(r'[0-9.-]?[0-9][0-9.-]?')\n",
    "\n",
    "TOKEN_URL = '__URL'\n",
    "#TOKEN_HANDLE = '__HANDLE'\n",
    "TOKEN_NUM = '__NUM'\n",
    "\n",
    "STOPWORDS_EN = set(stopwords.words('english') + [\"i've\"])\n",
    "STOP_PUNCT = set('.\"\\'&”“’,:;/*()[]{}')\n",
    "\n",
    "def normalize_token(token):\n",
    "    for regex, marker in [(REGEX_URL, TOKEN_URL)]: #, (REGEX_NUM, TOKEN_NUM)]:\n",
    "        if re.match(regex, token):\n",
    "            return marker\n",
    "    return token\n",
    "\n",
    "def get_wordnet_pos(pos):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos[0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def normalize_text(text, remove_stopwords=True, use_stemmer=True, remove_prefixes=True):\n",
    "    tokenizer = TweetTokenizer(preserve_case=False)\n",
    "    #stemmer = SnowballStemmer('english')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # if the first token is a handler, it's normally irrelevant\n",
    "    if tokens[0].startswith('@'):\n",
    "        tokens.pop(0)\n",
    "\n",
    "    ntokens = []\n",
    "    \n",
    "    # STEP 1: cleanup, formatting\n",
    "    for token in tokens:\n",
    "        ntoken = normalize_token(token)\n",
    "        \n",
    "        if remove_prefixes and any(token.startswith(c) for c in ['@', '#']):\n",
    "            ntoken = ntoken[1:]\n",
    "        if len(ntoken) == 0:\n",
    "            continue      \n",
    "        \n",
    "        ntokens.append(ntoken)\n",
    "    \n",
    "    if len(ntokens) == 0:\n",
    "        return ''\n",
    "    \n",
    "    # STEP 2: NLP tagging\n",
    "    pos_tags = nltk.pos_tag(ntokens)\n",
    "    \n",
    "    # STEP 3: \"semantic\" cleaning\n",
    "    ltokens = []\n",
    "    for token, pos in pos_tags:\n",
    "        if token in STOP_PUNCT:\n",
    "            continue\n",
    "        if remove_stopwords and token in STOPWORDS_EN:\n",
    "            continue\n",
    "        if pos == 'CD' or re.match(REGEX_NUM, token):\n",
    "            ltoken = TOKEN_NUM\n",
    "        else:\n",
    "            ltoken = lemmatizer.lemmatize(token, get_wordnet_pos(pos))\n",
    "        ltokens.append(ltoken)\n",
    "           \n",
    "    return ' '.join(ltokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def normalize_trivial(tweet):\n",
    "    tweet = ''.join(c for c in tweet if c not in string.punctuation)\n",
    "    tweet = re.sub('((www\\S+)|(http\\S+))', 'urlsite', tweet)\n",
    "    tweet = re.sub(r'\\d+', 'contnum', tweet)\n",
    "    tokens = re.split(r'\\s+', tweet.lower().strip())\n",
    "    ntokens = [t for t in tokens if len(t) > 0 and t not in STOPWORDS_EN]\n",
    "    return ' '.join(ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTRAL: @VirginAmerica What @dhepburn said.\n",
      ">> dhepburn say\n",
      "\n",
      "POSITIVE: @VirginAmerica plus you've added commercials to the experience... tacky.\n",
      ">> plus added commercial experience ... tacky\n",
      "\n",
      "NEUTRAL: @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
      ">> today ... must mean need take another trip !\n",
      "\n",
      "NEGATIVE: @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
      ">> really aggressive blast obnoxious entertainment guest face little recourse\n",
      "\n",
      "NEGATIVE: @VirginAmerica and it's a really big bad thing about it\n",
      ">> really big bad thing\n",
      "\n",
      "NEGATIVE: @VirginAmerica seriously would pay $30 a flight for seats that didn't have this playing.\n",
      "it's really the only bad thing about flying VA\n",
      ">> seriously would pay $ __NUM flight seat playing really bad thing fly va\n",
      "\n",
      "POSITIVE: @VirginAmerica yes, nearly every time I fly VX this “ear worm” won’t go away :)\n",
      ">> yes nearly every time fly vx ear worm go away :)\n",
      "\n",
      "NEUTRAL: @VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP\n",
      ">> really miss prime opportunity men without hat parody __URL\n",
      "\n",
      "POSITIVE: @virginamerica Well, I didn't…but NOW I DO! :-D\n",
      ">> well … ! :-D\n",
      "\n",
      "POSITIVE: @VirginAmerica it was amazing, and arrived an hour early. You're too good to me.\n",
      ">> amaze arrive hour early good\n",
      "\n",
      "NEUTRAL: @VirginAmerica did you know that suicide is the second leading cause of death among teens 10-24\n",
      ">> know suicide second leading cause death among teen __NUM\n",
      "\n",
      "POSITIVE: @VirginAmerica I &lt;3 pretty graphics. so much better than minimal iconography. :D\n",
      ">> <3 pretty graphic much good minimal iconography :D\n",
      "\n",
      "POSITIVE: @VirginAmerica This is such a great deal! Already thinking about my 2nd trip to @Australia &amp; I haven't even gone on my 1st trip yet! ;p\n",
      ">> great deal ! already think __NUM trip australia even go __NUM trip yet ! ;p\n",
      "\n",
      "POSITIVE: @VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn\n",
      ">> virginmedia i'm fly fabulous seductive sky ! u take stress away travel __URL\n",
      "\n",
      "POSITIVE: @VirginAmerica Thanks!\n",
      ">> thanks !\n",
      "\n",
      "NEGATIVE: @VirginAmerica SFO-PDX schedule is still MIA.\n",
      ">> sfo-pdx schedule still mia\n",
      "\n",
      "POSITIVE: @VirginAmerica So excited for my first cross country flight LAX to MCO I've heard nothing but great things about Virgin America. #29DaysToGo\n",
      ">> excited first cross country flight lax mco heard nothing great thing virgin america __NUM\n",
      "\n",
      "NEGATIVE: @VirginAmerica  I flew from NYC to SFO last week and couldn't fully sit in my seat due to two large gentleman on either side of me. HELP!\n",
      ">> fly nyc sfo last week fully sit seat due __NUM large gentleman either side help !\n",
      "\n",
      "POSITIVE: I ❤️ flying @VirginAmerica. ☺️👍\n",
      ">> ❤ ️ fly virginamerica ☺ ️ 👍\n",
      "\n",
      "POSITIVE: @VirginAmerica you know what would be amazingly awesome? BOS-FLL PLEASE!!!!!!! I want to fly with only you.\n",
      ">> know would amazingly awesome ? bos-fll please ! ! ! want fly\n",
      "\n",
      "NEGATIVE: @VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select???\n",
      ">> first fare may __NUM time carrier seat available select ? ? ?\n",
      "\n",
      "POSITIVE: @VirginAmerica I love this graphic. http://t.co/UT5GrRwAaA\n",
      ">> love graphic __URL\n",
      "\n",
      "POSITIVE: @VirginAmerica I love the hipster innovation. You are a feel good brand.\n",
      ">> love hipster innovation feel good brand\n",
      "\n",
      "NEUTRAL: @VirginAmerica will you be making BOS&gt;LAS non stop permanently anytime soon?\n",
      ">> make bos > la non stop permanently anytime soon ?\n",
      "\n",
      "NEGATIVE: @VirginAmerica you guys messed up my seating.. I reserved seating with my friends and you guys gave my seat away ... 😡 I want free internet\n",
      ">> guy mess seating .. reserve seat friend guy give seat away ... 😡 want free internet\n",
      "\n",
      "NEGATIVE: @VirginAmerica status match program.  I applied and it's been three weeks.  Called and emailed with no response.\n",
      ">> status match program apply __NUM week call email response\n",
      "\n",
      "NEGATIVE: @VirginAmerica What happened 2 ur vegan food options?! At least say on ur site so i know I won't be able 2 eat anything for next 6 hrs #fail\n",
      ">> happen __NUM ur vegan food option ? ! least say ur site know able __NUM eat anything next __NUM hr fail\n",
      "\n",
      "NEUTRAL: @VirginAmerica do you miss me? Don't worry we'll be together very soon.\n",
      ">> miss ? worry we'll together soon\n",
      "\n",
      "NEGATIVE: @VirginAmerica amazing to me that we can't get any cold air from the vents. #VX358 #noair #worstflightever #roasted #SFOtoBOS\n",
      ">> amaze can't get cold air vent vx358 noair worstflightever roast sfotobos\n",
      "\n",
      "NEUTRAL: @VirginAmerica LAX to EWR - Middle seat on a red eye. Such a noob maneuver. #sendambien #andchexmix\n",
      ">> lax ewr - middle seat red eye noob maneuver sendambien andchexmix\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_normalization(_df):\n",
    "    for i, row in _df.iterrows():\n",
    "        print(row.sentiment.upper() + \": \" + row.text + '\\n>> ' + normalize_text(row.text) + '\\n')\n",
    "\n",
    "show_normalization(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE: @SouthwestAir pls help me get this resolved &amp; reimbursement made.  gracias, rico; pls send me private msg with phone number or email address\n",
      ">> pls help get resolve reimbursement make gracias rico pls send private msg phone number email address\n",
      "\n",
      "NEGATIVE: @USAirways you guys suck at JFK tonight -- oh this MORNING!!!\n",
      ">> guy suck jfk tonight - - oh morning ! ! !\n",
      "\n",
      "NEUTRAL: @JetBlue Domestic.  To be clear -- I do not have to sit in (your lovely) terminal, just need to be there 1 hour prior to boarding?  Thanks!\n",
      ">> domestic clear - - sit lovely terminal need __NUM hour prior board ? thanks !\n",
      "\n",
      "NEGATIVE: @united they held the flight for our group of nearly 20 people.\n",
      ">> hold flight group nearly __NUM people\n",
      "\n",
      "NEGATIVE: @USAirways Gave up after more than 2 hours on hold. Still need that receipt; last time it was promised, it never arrived. Help?!\n",
      ">> give __NUM hour hold still need receipt last time promise never arrive help ? !\n",
      "\n",
      "NEGATIVE: @united Without baggage for 5 days and can't get an update from Houston airport since Monday. Worst service ever!\n",
      ">> without baggage __NUM day can't get update houston airport since monday bad service ever !\n",
      "\n",
      "NEGATIVE: @united This is with regard to a flight from a couple weeks ago. I'm very frustrated with your policies &amp; expressing that.\n",
      ">> regard flight couple week ago i'm frustrated policy express\n",
      "\n",
      "POSITIVE: @SouthwestAir great cabin and flight crew this morning on #578. A great smile and happy staff are signs of a happy company. Thanks.\n",
      ">> great cabin flight crew morning __NUM great smile happy staff sign happy company thanks\n",
      "\n",
      "NEGATIVE: @USAirways getting extremely frustrated w/ the phone/online service for merging frequent flyer miles.\n",
      ">> get extremely frustrate w phone online service merge frequent flyer mile\n",
      "\n",
      "NEUTRAL: @JetBlue who do you think is gonna win Mayweather or Pacquiao?\n",
      ">> think gonna win mayweather pacquiao ?\n",
      "\n",
      "NEUTRAL: @AmericanAir Do you have any flights with lie flat seating from STL to PDX around the date of March 5?\n",
      ">> flight lie flat seating stl pdx around date march __NUM ?\n",
      "\n",
      "NEGATIVE: @SouthwestAir do these scavenger hunt  locations have anything in common because I'm playing detective trying to figure out the one for ATL.\n",
      ">> scavenger hunt location anything common i'm play detective try figure one atl\n",
      "\n",
      "NEGATIVE: @united it was credit from my last trip that never came in the mail!\n",
      ">> credit last trip never come mail !\n",
      "\n",
      "NEUTRAL: @United are you able to see if there are seats open on another flight??\n",
      ">> able see seat open another flight ? ?\n",
      "\n",
      "NEGATIVE: @AmericanAir how do you NOT do maintenance on #MD80 while it sits for two days? Frozen lines found after its boarded? Come on! #faail #mci\n",
      ">> maintenance MD80 sit __NUM day ? frozen line find board ? come ! faail mci\n",
      "\n",
      "NEGATIVE: @AmericanAir trying to get home is beyond complicated. It's should not be this hard. Students are split up and we will not fly AA ever again\n",
      ">> try get home beyond complicate hard student split fly aa ever\n",
      "\n",
      "NEUTRAL: @united hey, I missed my outbound flight - can I still use my return ticket?\n",
      ">> hey miss outbound flight - still use return ticket ?\n",
      "\n",
      "NEUTRAL: @AmericanAir .. UMM hello?\n",
      ">> .. umm hello ?\n",
      "\n",
      "POSITIVE: Thank you. “@AmericanAir: @jlhalldc Customer Relations will review your concerns and contact you back directly, John.”\n",
      ">> thank americanair jlhalldc customer relation review concern contact back directly john\n",
      "\n",
      "NEGATIVE: @JetBlue. A bunch of flights are delayed from FFL to Northeast destinations. No announcements at the gate. What's going on?\n",
      ">> bunch flight delay ffl northeast destination announcement gate what's go ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_normalization(df.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just do a binary classification for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>dhepburn say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercial experience ... tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>today ... must mean need take another trip !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay $ __NUM flight seat playin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>really miss prime opportunity men without hat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>positive</td>\n",
       "      <td>well … ! :-D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>amaze arrive hour early good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>know suicide second leading cause death among ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>positive</td>\n",
       "      <td>&lt;3 pretty graphic much good minimal iconograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>positive</td>\n",
       "      <td>great deal ! already think __NUM trip australi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@VirginAmerica @virginmedia I'm flying your #f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>virginmedia i'm fly fabulous seductive sky ! u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>positive</td>\n",
       "      <td>thanks !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>negative</td>\n",
       "      <td>sfo-pdx schedule still mia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@VirginAmerica So excited for my first cross c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>excited first cross country flight lax mco hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>negative</td>\n",
       "      <td>fly nyc sfo last week fully sit seat due __NUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I ❤️ flying @VirginAmerica. ☺️👍</td>\n",
       "      <td>positive</td>\n",
       "      <td>❤ ️ fly virginamerica ☺ ️ 👍</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@VirginAmerica you know what would be amazingl...</td>\n",
       "      <td>positive</td>\n",
       "      <td>know would amazingly awesome ? bos-fll please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@VirginAmerica why are your first fares in May...</td>\n",
       "      <td>negative</td>\n",
       "      <td>first fare may __NUM time carrier seat availab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@VirginAmerica I love this graphic. http://t.c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love graphic __URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@VirginAmerica I love the hipster innovation. ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>love hipster innovation feel good brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@VirginAmerica will you be making BOS&amp;gt;LAS n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>make bos &gt; la non stop permanently anytime soon ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@VirginAmerica you guys messed up my seating.....</td>\n",
       "      <td>negative</td>\n",
       "      <td>guy mess seating .. reserve seat friend guy gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@VirginAmerica status match program.  I applie...</td>\n",
       "      <td>negative</td>\n",
       "      <td>status match program apply __NUM week call ema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@VirginAmerica What happened 2 ur vegan food o...</td>\n",
       "      <td>negative</td>\n",
       "      <td>happen __NUM ur vegan food option ? ! least sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@VirginAmerica do you miss me? Don't worry we'...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>miss ? worry we'll together soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@VirginAmerica amazing to me that we can't get...</td>\n",
       "      <td>negative</td>\n",
       "      <td>amaze can't get cold air vent vx358 noair wors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@VirginAmerica LAX to EWR - Middle seat on a r...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>lax ewr - middle seat red eye noob maneuver se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text sentiment  \\\n",
       "0                 @VirginAmerica What @dhepburn said.   neutral   \n",
       "1   @VirginAmerica plus you've added commercials t...  positive   \n",
       "2   @VirginAmerica I didn't today... Must mean I n...   neutral   \n",
       "3   @VirginAmerica it's really aggressive to blast...  negative   \n",
       "4   @VirginAmerica and it's a really big bad thing...  negative   \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...  negative   \n",
       "6   @VirginAmerica yes, nearly every time I fly VX...  positive   \n",
       "7   @VirginAmerica Really missed a prime opportuni...   neutral   \n",
       "8     @virginamerica Well, I didn't…but NOW I DO! :-D  positive   \n",
       "9   @VirginAmerica it was amazing, and arrived an ...  positive   \n",
       "10  @VirginAmerica did you know that suicide is th...   neutral   \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...  positive   \n",
       "12  @VirginAmerica This is such a great deal! Alre...  positive   \n",
       "13  @VirginAmerica @virginmedia I'm flying your #f...  positive   \n",
       "14                             @VirginAmerica Thanks!  positive   \n",
       "15      @VirginAmerica SFO-PDX schedule is still MIA.  negative   \n",
       "16  @VirginAmerica So excited for my first cross c...  positive   \n",
       "17  @VirginAmerica  I flew from NYC to SFO last we...  negative   \n",
       "18                    I ❤️ flying @VirginAmerica. ☺️👍  positive   \n",
       "19  @VirginAmerica you know what would be amazingl...  positive   \n",
       "20  @VirginAmerica why are your first fares in May...  negative   \n",
       "21  @VirginAmerica I love this graphic. http://t.c...  positive   \n",
       "22  @VirginAmerica I love the hipster innovation. ...  positive   \n",
       "23  @VirginAmerica will you be making BOS&gt;LAS n...   neutral   \n",
       "24  @VirginAmerica you guys messed up my seating.....  negative   \n",
       "25  @VirginAmerica status match program.  I applie...  negative   \n",
       "26  @VirginAmerica What happened 2 ur vegan food o...  negative   \n",
       "27  @VirginAmerica do you miss me? Don't worry we'...   neutral   \n",
       "28  @VirginAmerica amazing to me that we can't get...  negative   \n",
       "29  @VirginAmerica LAX to EWR - Middle seat on a r...   neutral   \n",
       "\n",
       "                                            norm_text  \n",
       "0                                        dhepburn say  \n",
       "1          plus added commercial experience ... tacky  \n",
       "2        today ... must mean need take another trip !  \n",
       "3   really aggressive blast obnoxious entertainmen...  \n",
       "4                                really big bad thing  \n",
       "5   seriously would pay $ __NUM flight seat playin...  \n",
       "6    yes nearly every time fly vx ear worm go away :)  \n",
       "7   really miss prime opportunity men without hat ...  \n",
       "8                                        well … ! :-D  \n",
       "9                        amaze arrive hour early good  \n",
       "10  know suicide second leading cause death among ...  \n",
       "11  <3 pretty graphic much good minimal iconograph...  \n",
       "12  great deal ! already think __NUM trip australi...  \n",
       "13  virginmedia i'm fly fabulous seductive sky ! u...  \n",
       "14                                           thanks !  \n",
       "15                         sfo-pdx schedule still mia  \n",
       "16  excited first cross country flight lax mco hea...  \n",
       "17  fly nyc sfo last week fully sit seat due __NUM...  \n",
       "18                        ❤ ️ fly virginamerica ☺ ️ 👍  \n",
       "19  know would amazingly awesome ? bos-fll please ...  \n",
       "20  first fare may __NUM time carrier seat availab...  \n",
       "21                                 love graphic __URL  \n",
       "22            love hipster innovation feel good brand  \n",
       "23  make bos > la non stop permanently anytime soon ?  \n",
       "24  guy mess seating .. reserve seat friend guy gi...  \n",
       "25  status match program apply __NUM week call ema...  \n",
       "26  happen __NUM ur vegan food option ? ! least sa...  \n",
       "27                   miss ? worry we'll together soon  \n",
       "28  amaze can't get cold air vent vx358 noair wors...  \n",
       "29  lax ewr - middle seat red eye noob maneuver se...  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply normalization to ALL text\n",
    "df['norm_text'] = df.text.apply(normalize_text)\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11541, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercial experience ... tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay $ __NUM flight seat playin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away :)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment  \\\n",
       "1  @VirginAmerica plus you've added commercials t...  positive   \n",
       "3  @VirginAmerica it's really aggressive to blast...  negative   \n",
       "4  @VirginAmerica and it's a really big bad thing...  negative   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...  negative   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...  positive   \n",
       "\n",
       "                                           norm_text  \n",
       "1         plus added commercial experience ... tacky  \n",
       "3  really aggressive blast obnoxious entertainmen...  \n",
       "4                               really big bad thing  \n",
       "5  seriously would pay $ __NUM flight seat playin...  \n",
       "6   yes nearly every time fly vx ear worm go away :)  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary = df[df.sentiment != 'neutral']\n",
    "print(df_binary.shape)\n",
    "df_binary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 7732; test: 3809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_test, label_train, label_test = train_test_split(df_binary['norm_text'], df_binary['sentiment'], test_size=0.33, random_state=0)\n",
    "\n",
    "print(\"Training: %d; test: %d\" % (len(text_train), len(text_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomian NB using counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "\n",
    "y_train = [LABELS[l] for l in label_train]\n",
    "y_test = [LABELS[l] for l in label_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counter = CountVectorizer()\n",
    "X_train = counter.fit_transform(text_train)\n",
    "X_test = counter.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boyfriend love imaginedragons since __NUM would awesome go vegas event way help ?\n",
      "finally thx\n",
      "flight delay __NUM hour insane every flight make nyc\n",
      "thanks much !\n",
      "haha boarding pas __NUM board plane gate agent tell go __NUM i'm worry\n",
      "__NUM smf jfk !\n",
      "joanna wonderful job ! thank ?\n",
      "enough staff rude ignored passenger think accept whatever reason\n",
      "delay understandable look time flight boarding time weird !\n",
      "seriously attendant go awol __NUM min flight delayed lite match either __URL\n"
     ]
    }
   ],
   "source": [
    "for row in text_train[:10]:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7732, 7378)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9389549922400414\n",
      "0.8994486741927015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_class_counts(df):\n",
    "    class_counts = df.groupby('sentiment').count()\n",
    "    min_size = class_counts['text'].min()\n",
    "    classes = []\n",
    "    for label in class_counts.index:\n",
    "        classes.append(df.copy()[df.sentiment == label][:min_size])\n",
    "    return pd.concat(classes, ignore_index=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4726, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bin_bal = balance_class_counts(df_binary)\n",
    "df_bin_bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB using TF-IDF, direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7732, 7173)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "v_train = vectorizer.fit_transform(text_train)\n",
    "v_test = vectorizer.transform(text_test)\n",
    "\n",
    "X_train = v_train.toarray()\n",
    "X_test = v_test.toarray()\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8043197102948785\n",
      "0.639012864268837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB using TF-IDF and feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7732, 717)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(v_train, y_train)\n",
    "vs_train = selector.transform(v_train)\n",
    "vs_test  = selector.transform(v_test)\n",
    "\n",
    "X_train = vs_train.toarray()\n",
    "X_test = vs_test.toarray()\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625193998965339\n",
      "0.8049356786558152\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with kernel=linear, C=1.000000\n",
      "Trying with kernel=linear, C=10.000000\n",
      "Trying with kernel=linear, C=100.000000\n",
      "Trying with kernel=linear, C=1000.000000\n",
      "Trying with kernel=rbf, C=1.000000\n",
      "Trying with kernel=rbf, C=10.000000\n",
      "Trying with kernel=rbf, C=100.000000\n",
      "Trying with kernel=rbf, C=1000.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "# we try different values of C and kernel\n",
    "kernels = ['linear', 'rbf']\n",
    "Cs = [1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "results = []\n",
    "\n",
    "for kernel in kernels:\n",
    "    for cc in Cs:\n",
    "        print('Trying with kernel=%s, C=%f' % (kernel, cc))        \n",
    "        clf = SVC(kernel=kernel, C=cc, gamma='auto') # setting gamma=auto to avoid warning\n",
    "        t0 = time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        t1 = time()\n",
    "        score_train = clf.score(X_train, y_train)\n",
    "        score_test = clf.score(X_test, y_test)\n",
    "        t2 = time()\n",
    "        # (kernel, c, train score, test score, train time, score time)\n",
    "        results.append((kernel, cc, score_train, score_test, t1 - t0, t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>time_train</th>\n",
       "      <th>time_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.919814</td>\n",
       "      <td>0.904962</td>\n",
       "      <td>19.710320</td>\n",
       "      <td>25.384943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.947362</td>\n",
       "      <td>0.906800</td>\n",
       "      <td>15.906641</td>\n",
       "      <td>19.047550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.899974</td>\n",
       "      <td>18.055134</td>\n",
       "      <td>16.144613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.953440</td>\n",
       "      <td>0.898399</td>\n",
       "      <td>35.974997</td>\n",
       "      <td>15.673101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>0.789709</td>\n",
       "      <td>26.160089</td>\n",
       "      <td>37.076061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.818676</td>\n",
       "      <td>0.813599</td>\n",
       "      <td>26.876825</td>\n",
       "      <td>36.623412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.883989</td>\n",
       "      <td>0.878971</td>\n",
       "      <td>23.059513</td>\n",
       "      <td>30.147097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.935334</td>\n",
       "      <td>0.909163</td>\n",
       "      <td>17.150419</td>\n",
       "      <td>22.355724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel       C  score_train  score_test  time_train  time_score\n",
       "0  linear     1.0     0.919814    0.904962   19.710320   25.384943\n",
       "1  linear    10.0     0.947362    0.906800   15.906641   19.047550\n",
       "2  linear   100.0     0.952535    0.899974   18.055134   16.144613\n",
       "3  linear  1000.0     0.953440    0.898399   35.974997   15.673101\n",
       "4     rbf     1.0     0.797982    0.789709   26.160089   37.076061\n",
       "5     rbf    10.0     0.818676    0.813599   26.876825   36.623412\n",
       "6     rbf   100.0     0.883989    0.878971   23.059513   30.147097\n",
       "7     rbf  1000.0     0.935334    0.909163   17.150419   22.355724"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_df = pd.DataFrame(results, columns=['kernel', 'C', 'score_train', 'score_test', 'time_train', 'time_score'])\n",
    "svc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496896016554578\n",
      "0.8724074560252034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes about pre-processing:\n",
    "- stemming did not seem to help\n",
    "- in fact, lemmatization using POS tags ended up in _slightly worse_ results that just simple normalization\n",
    "- the exception is the Decision Tree, it actually got better with lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kernel</th>\n",
       "      <th>C</th>\n",
       "      <th>score_train</th>\n",
       "      <th>score_test</th>\n",
       "      <th>time_train</th>\n",
       "      <th>time_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.918391</td>\n",
       "      <td>0.900761</td>\n",
       "      <td>17.343747</td>\n",
       "      <td>21.201815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.945939</td>\n",
       "      <td>0.901286</td>\n",
       "      <td>13.586512</td>\n",
       "      <td>15.813359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.948267</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>16.264316</td>\n",
       "      <td>13.488832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.949690</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>36.859171</td>\n",
       "      <td>12.856801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>0.789709</td>\n",
       "      <td>22.111068</td>\n",
       "      <td>31.139696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.821133</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>21.581112</td>\n",
       "      <td>30.200040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.889938</td>\n",
       "      <td>0.885272</td>\n",
       "      <td>18.664486</td>\n",
       "      <td>25.444301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.938308</td>\n",
       "      <td>0.902862</td>\n",
       "      <td>15.291044</td>\n",
       "      <td>18.857582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kernel       C  score_train  score_test  time_train  time_score\n",
       "0  linear     1.0     0.918391    0.900761   17.343747   21.201815\n",
       "1  linear    10.0     0.945939    0.901286   13.586512   15.813359\n",
       "2  linear   100.0     0.948267    0.898661   16.264316   13.488832\n",
       "3  linear  1000.0     0.949690    0.898661   36.859171   12.856801\n",
       "4     rbf     1.0     0.797982    0.789709   22.111068   31.139696\n",
       "5     rbf    10.0     0.821133    0.815700   21.581112   30.200040\n",
       "6     rbf   100.0     0.889938    0.885272   18.664486   25.444301\n",
       "7     rbf  1000.0     0.938308    0.902862   15.291044   18.857582"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_df = pd.DataFrame(results, columns=['kernel', 'C', 'score_train', 'score_test', 'time_train', 'time_score'])\n",
    "svc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
